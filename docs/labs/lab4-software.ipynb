{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<div align=\"center\">\n",
    "  <a href=\"https://deepwok.github.io/\">\n",
    "    <img src=\"../imgs/deepwok.png\" alt=\"Logo\" width=\"160\" height=\"160\">\n",
    "  </a>\n",
    "\n",
    "  <h1 align=\"center\">Lab 4 for Advanced Deep Learning Systems (ADLS) - Software Stream</h1>\n",
    "\n",
    "  <p align=\"center\">\n",
    "    ELEC70109/EE9-AML3-10/EE9-AO25\n",
    "    <br />\n",
    "\t\tWritten by\n",
    "    <a href=\"https://aaron-zhao123.github.io/\">Aaron Zhao, Cheng Zhang, Pedro Gimenes </a>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General introduction\n",
    "In this lab, you will learn how to use the search functionality in the software stack of MASE to implement a Network Architecture Search.\n",
    "\n",
    "There are in total 4 tasks you would need to finish, there is also 1 optional task.\n",
    "\n",
    "What is Network Architecture Search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Handwritten JSC Network\n",
    "\n",
    "We follow a similar procedure of what you have tried in lab3 to setup the dataset, copy and paste the following code snippet to a file, and name it lab4.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity, get_logger\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from torch import nn\n",
    "from chop.passes.graph.utils import get_parent_name\n",
    "from chop.passes import report_graph_analysis_pass\n",
    "from chop.passes import report_graph_analysis_pass\n",
    "\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")\n",
    "\n",
    "logger = get_logger(\"chop\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "batch_size = 8\n",
    "model_name = \"jsc-tiny\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "dummy_in = {\"x\": next(iter(data_module.train_dataloader()))[0]}\n",
    "\n",
    "# create the graph\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=5, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mg.modules['seq_blocks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we are going to use a slightly different network, so we define it as a Pytorch model, copy and paste this snippet also to `lab4.py`.\n",
    "\n",
    "**Note**\n",
    "\n",
    "MASE integrates seamlessly with native Pytorch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (4): Linear(in_features=16, out_features=5, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from chop.passes.graph.utils import get_parent_name\n",
    "from chop.passes import report_graph_analysis_pass\n",
    "\n",
    "# define a new model\n",
    "class JSC_Three_Linear_Layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JSC_Three_Linear_Layers, self).__init__()\n",
    "        self.seq_blocks = nn.Sequential(\n",
    "            nn.BatchNorm1d(16),  # 0\n",
    "            nn.ReLU(16),  # 1\n",
    "            nn.Linear(16, 16),  # linear  2\n",
    "            nn.Linear(16, 16),  # linear  3\n",
    "            nn.Linear(16, 5),   # linear  4\n",
    "            nn.ReLU(5),  # 5\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq_blocks(x)\n",
    "\n",
    "\n",
    "model = JSC_Three_Linear_Layers()\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# report the graph\n",
    "print(mg.modules['seq_blocks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture Modification as a Transformation Pass\n",
    "\n",
    "Similar to what you have done in `lab2`, one can also implement a change in model architecture as a transformation pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (4): Linear(in_features=32, out_features=5, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def instantiate_linear(in_features, out_features, bias):\n",
    "    if bias is not None:\n",
    "        bias = True\n",
    "    return nn.Linear(\n",
    "        in_features=in_features,\n",
    "        out_features=out_features,\n",
    "        bias=bias)\n",
    "\n",
    "def redefine_linear_transform_pass(graph, pass_args=None):\n",
    "    main_config = pass_args.pop('config')\n",
    "    default = main_config.pop('default', None)\n",
    "    if default is None:\n",
    "        raise ValueError(f\"default value must be provided.\")\n",
    "    i = 0\n",
    "    for node in graph.fx_graph.nodes:\n",
    "        i += 1\n",
    "        # if node name is not matched, it won't be tracked\n",
    "        config = main_config.get(node.name, default)['config']\n",
    "        name = config.get(\"name\", None)\n",
    "        if name is not None:\n",
    "            ori_module = graph.modules[node.target]\n",
    "            in_features = ori_module.in_features\n",
    "            out_features = ori_module.out_features\n",
    "            bias = ori_module.bias\n",
    "            if name == \"output_only\":\n",
    "                out_features = out_features * config[\"channel_multiplier\"]\n",
    "            elif name == \"both\":\n",
    "                in_features = in_features * config[\"channel_multiplier\"]\n",
    "                out_features = out_features * config[\"channel_multiplier\"]\n",
    "            elif name == \"input_only\":\n",
    "                in_features = in_features * config[\"channel_multiplier\"]\n",
    "            new_module = instantiate_linear(in_features, out_features, bias)\n",
    "            parent_name, name = get_parent_name(node.target)\n",
    "            setattr(graph.modules[parent_name], name, new_module)\n",
    "    return graph, {}\n",
    "\n",
    "\n",
    "\n",
    "pass_config = {\n",
    "\"by\": \"name\",\n",
    "\"default\": {\"config\": {\"name\": None}},\n",
    "\"seq_blocks_2\": {\n",
    "    \"config\": {\n",
    "        \"name\": \"output_only\",\n",
    "        # weight\n",
    "        \"channel_multiplier\": 2,\n",
    "        }\n",
    "    },\n",
    "\"seq_blocks_3\": {\n",
    "    \"config\": {\n",
    "        \"name\": \"both\",\n",
    "        \"channel_multiplier\": 2,\n",
    "        }\n",
    "    },\n",
    "\"seq_blocks_4\": {\n",
    "    \"config\": {\n",
    "        \"name\": \"input_only\",\n",
    "        \"channel_multiplier\": 2,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "# this performs the architecture transformation based on the config\n",
    "mg, _ = redefine_linear_transform_pass(\n",
    "    graph=mg, pass_args={\"config\": pass_config})\n",
    "\n",
    "# report the graph\n",
    "print(mg.modules['seq_blocks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modified network features linear layers expanded to double their size, yet itâ€™s unusual to sequence three linear layers consecutively without interposing any non-linear activations (do you know why?).\n",
    "\n",
    "So we are interested in a modified network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=16, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define a new model\n",
    "class JSC_Three_Linear_Layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JSC_Three_Linear_Layers, self).__init__()\n",
    "        self.seq_blocks = nn.Sequential(\n",
    "            nn.BatchNorm1d(16),  # 0\n",
    "            nn.ReLU(16),  # 1\n",
    "            nn.Linear(16, 16),  # linear seq_2\n",
    "            nn.ReLU(16),  # 3\n",
    "            nn.Linear(16, 16),  # linear seq_4\n",
    "            nn.ReLU(16),  # 5\n",
    "            nn.Linear(16, 5),  # linear seq_6\n",
    "            nn.ReLU(5),  # 7\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq_blocks(x)\n",
    "    \n",
    "model = JSC_Three_Linear_Layers()\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# report the graph\n",
    "print(mg.modules['seq_blocks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Can you edit your code, so that we can modify the above network to have layers expanded to double their sizes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pass_config = {\n",
    "\"by\": \"name\",\n",
    "\"default\": {\"config\": {\"name\": None}},\n",
    "\"seq_blocks_2\": {\n",
    "    \"config\": {\n",
    "        \"name\": \"output_only\",\n",
    "        # weight\n",
    "        \"channel_multiplier\": 2,\n",
    "        }\n",
    "    },\n",
    "\"seq_blocks_4\": {\n",
    "    \"config\": {\n",
    "        \"name\": \"both\",\n",
    "        \"channel_multiplier\": 2,\n",
    "        }\n",
    "    },\n",
    "\"seq_blocks_6\": {\n",
    "    \"config\": {\n",
    "        \"name\": \"input_only\",\n",
    "        \"channel_multiplier\": 2,\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': GraphModule(\n",
      "  (seq_blocks): Module(\n",
      "    (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=32, out_features=5, bias=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "  )\n",
      "), 'seq_blocks': Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=32, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      "), 'seq_blocks.0': BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), 'seq_blocks.1': ReLU(inplace=True), 'seq_blocks.2': Linear(in_features=16, out_features=32, bias=True), 'seq_blocks.3': ReLU(inplace=True), 'seq_blocks.4': Linear(in_features=32, out_features=32, bias=True), 'seq_blocks.5': ReLU(inplace=True), 'seq_blocks.6': Linear(in_features=32, out_features=5, bias=True), 'seq_blocks.7': ReLU(inplace=True)}\n"
     ]
    }
   ],
   "source": [
    "# this performs the architecture transformation based on the config\n",
    "mg, _ = redefine_linear_transform_pass(\n",
    "    graph=mg, pass_args={\"config\": new_pass_config})\n",
    "\n",
    "# report the graph\n",
    "print(mg.modules['seq_blocks_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In `lab3`, we have implemented a grid search, can we use the grid search to search for the best channel multiplier value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!./ch search --config configs/examples/jsc_lab_4_channel_mul.toml --load ../mase_output/jsc-toy-lab-1_classification_jsc_2024-01-26/software/training_ckpts/best.ckpt --load-type pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_config_2 = {\n",
    "\"by\": \"name\",\n",
    "\"default\": {\"config\": {\"name\": None}},\n",
    "\"seq_blocks_2\": {\n",
    "    \"config\": {\n",
    "        \"name\": \"output_only\",\n",
    "        # weight\n",
    "        \"channel_multiplier\": 2,\n",
    "        }\n",
    "    },\n",
    "\"seq_blocks_4\": {\n",
    "    \"config\": {\n",
    "        \"name\": \"both\",\n",
    "        \"channel_multiplier\": 2,\n",
    "        }\n",
    "    },\n",
    "\"seq_blocks_6\": {\n",
    "    \"config\": {\n",
    "        \"name\": \"input_only\",\n",
    "        \"channel_multiplier\": 2,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "import copy\n",
    "# build a new search space\n",
    "channel_multipliers = [2,4,6,8]\n",
    "\n",
    "search_spaces = []\n",
    "for d_config in channel_multipliers:\n",
    "    pass_config_2['seq_blocks_2']['config']['channel_multiplier'] = d_config\n",
    "    pass_config_2['seq_blocks_4']['config']['channel_multiplier'] = d_config\n",
    "    pass_config_2['seq_blocks_6']['config']['channel_multiplier'] = d_config\n",
    "\n",
    "    # dict.copy() and dict(dict) only perform shallow copies\n",
    "    # in fact, only primitive data types in python are doing implicit copy when a = b happens\n",
    "    search_spaces.append(copy.deepcopy(pass_config_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'by': 'name',\n",
       "  'default': {'config': {'name': None}},\n",
       "  'seq_blocks_2': {'config': {'name': 'output_only', 'channel_multiplier': 2}},\n",
       "  'seq_blocks_4': {'config': {'name': 'both', 'channel_multiplier': 2}},\n",
       "  'seq_blocks_6': {'config': {'name': 'input_only', 'channel_multiplier': 2}}},\n",
       " {'by': 'name',\n",
       "  'default': {'config': {'name': None}},\n",
       "  'seq_blocks_2': {'config': {'name': 'output_only', 'channel_multiplier': 4}},\n",
       "  'seq_blocks_4': {'config': {'name': 'both', 'channel_multiplier': 4}},\n",
       "  'seq_blocks_6': {'config': {'name': 'input_only', 'channel_multiplier': 4}}},\n",
       " {'by': 'name',\n",
       "  'default': {'config': {'name': None}},\n",
       "  'seq_blocks_2': {'config': {'name': 'output_only', 'channel_multiplier': 6}},\n",
       "  'seq_blocks_4': {'config': {'name': 'both', 'channel_multiplier': 6}},\n",
       "  'seq_blocks_6': {'config': {'name': 'input_only', 'channel_multiplier': 6}}},\n",
       " {'by': 'name',\n",
       "  'default': {'config': {'name': None}},\n",
       "  'seq_blocks_2': {'config': {'name': 'output_only', 'channel_multiplier': 8}},\n",
       "  'seq_blocks_4': {'config': {'name': 'both', 'channel_multiplier': 8}},\n",
       "  'seq_blocks_6': {'config': {'name': 'input_only', 'channel_multiplier': 8}}}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=256, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=256, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#new_mg = copy.deepcopy(mg)\n",
    "print(new_mg.modules['seq_blocks'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Multiplier: 2 \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=64, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=64, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: 4 \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: 6 \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=192, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=192, out_features=192, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=192, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: 8 \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=256, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=256, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from chop.passes.graph.transforms import (\n",
    "    quantize_transform_pass,\n",
    "    summarize_quantization_analysis_pass,\n",
    ")\n",
    "\n",
    "# mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "# mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "# mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "metric = MulticlassAccuracy(num_classes=5)\n",
    "num_batchs = 5\n",
    "# This first loop is basically our search strategy,\n",
    "# in this case, it is a simple brute force search\n",
    "\n",
    "recorded_accs = []\n",
    "for i, pass_config in enumerate(search_spaces):\n",
    "\n",
    "    # print the config multiplier\n",
    "    print('Config Multiplier:', pass_config['seq_blocks_4']['config']['channel_multiplier'], '\\n')\n",
    "    \n",
    "    # we need to make a deep copy of the graph and the config so that the original graph is used when we multiply the channels\n",
    "    config = copy.deepcopy(pass_config)\n",
    "    new_mg = copy.deepcopy(mg)\n",
    "\n",
    "    #Function to redefine the linear transform\n",
    "    new_mg , _ = redefine_linear_transform_pass(graph=new_mg, pass_args={\"config\": config})\n",
    "    print(new_mg.modules['seq_blocks'], '\\n')\n",
    "\n",
    "    j = 0\n",
    "\n",
    "    # this is the inner loop, where we also call it as a runner.\n",
    "    acc_avg, loss_avg = 0, 0\n",
    "    accs, losses = [], []\n",
    "    \n",
    "    for inputs in data_module.train_dataloader():\n",
    "        xs, ys = inputs\n",
    "        preds = mg.model(xs)\n",
    "        loss = torch.nn.functional.cross_entropy(preds, ys)\n",
    "        acc = metric(preds, ys)\n",
    "        accs.append(acc)\n",
    "        losses.append(loss)\n",
    "        if j > num_batchs:\n",
    "            break\n",
    "        j += 1\n",
    "    acc_avg = sum(accs) / len(accs)\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "    recorded_accs.append(acc_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.0655), tensor(0.1732), tensor(0.1988), tensor(0.2119)]\n"
     ]
    }
   ],
   "source": [
    "print(recorded_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You may have noticed, one problem with the channel multiplier is that it scales all layers uniformly, ideally, we would like to be able to construct networks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=64, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define a new model\n",
    "class JSC_Three_Linear_Layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JSC_Three_Linear_Layers, self).__init__()\n",
    "        self.seq_blocks = nn.Sequential(\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(16),\n",
    "            nn.Linear(16, 32),  # output scaled by 2\n",
    "            nn.ReLU(32),  # scaled by 2\n",
    "            nn.Linear(32, 64),  # input scaled by 2 but output scaled by 4\n",
    "            nn.ReLU(64),  # scaled by 4\n",
    "            nn.Linear(64, 5),  # scaled by 4\n",
    "            nn.ReLU(5),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq_blocks(x)\n",
    "    \n",
    "model = JSC_Three_Linear_Layers()\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# report the graph\n",
    "print(mg.modules['seq_blocks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_linear(in_features, out_features, bias):\n",
    "    if bias is not None:\n",
    "        bias = True\n",
    "    return nn.Linear(\n",
    "        in_features=in_features,\n",
    "        out_features=out_features,\n",
    "        bias=bias)\n",
    "\n",
    "def redefine_linear_transform_pass_non_uniform(graph, pass_args=None):\n",
    "    print('start')\n",
    "    main_config = pass_args.pop('config')\n",
    "    default = main_config.pop('default', None)\n",
    "    if default is None:\n",
    "        raise ValueError(f\"default value must be provided.\")\n",
    "    i = 0\n",
    "    for node in graph.fx_graph.nodes:\n",
    "        i += 1\n",
    "        # if node name is not matched, it won't be tracked\n",
    "        config = main_config.get(node.name, default)['config']\n",
    "        names = config.get(\"names\", None)\n",
    "        print(names)\n",
    "        if names is not None:\n",
    "            ori_module = graph.modules[node.target]\n",
    "            in_features = ori_module.in_features\n",
    "            out_features = ori_module.out_features\n",
    "            bias = ori_module.bias\n",
    "            for i, name in enumerate(names):\n",
    "                print(i,name)\n",
    "                if name == \"output_only\":\n",
    "                    out_features = out_features * config[\"channel_multiplier\"][i]\n",
    "                elif name == \"both\":\n",
    "                    in_features = in_features * config[\"channel_multiplier\"][i]\n",
    "                    out_features = out_features * config[\"channel_multiplier\"][i]\n",
    "                elif name == \"input_only\":\n",
    "                    in_features = in_features * config[\"channel_multiplier\"][i]\n",
    "            new_module = instantiate_linear(in_features, out_features, bias)\n",
    "            parent_name, name = get_parent_name(node.target)\n",
    "            setattr(graph.modules[parent_name], name, new_module)\n",
    "    return graph, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_config_3 = {\n",
    "\"by\": \"name\",\n",
    "\"default\": {\"config\": {\"name\": None}},\n",
    "\"seq_blocks_2\": {\n",
    "    \"config\": {\n",
    "        \"names\": [ \"output_only\"],\n",
    "        # weight\n",
    "        \"channel_multiplier\": [2],\n",
    "        }\n",
    "    },\n",
    "\"seq_blocks_4\": {\n",
    "    \"config\": {\n",
    "        \"names\": [\"input_only\",\"output_only\"],\n",
    "        \"channel_multiplier\": [2,2],\n",
    "        }\n",
    "    },\n",
    "\"seq_blocks_6\": {\n",
    "    \"config\": {\n",
    "        \"names\": [\"input_only\"],\n",
    "        \"channel_multiplier\": [2],\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "1 2\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "5 4\n",
      "5 5\n",
      "Dictionary 1:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 1}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [1, 1]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 1}} \n",
      "\n",
      "Dictionary 2:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 1}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [1, 2]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 2}} \n",
      "\n",
      "Dictionary 3:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 2}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [2, 1]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 1}} \n",
      "\n",
      "Dictionary 4:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 2}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [2, 2]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 2}} \n",
      "\n",
      "Dictionary 5:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 2}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [2, 3]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 3}} \n",
      "\n",
      "Dictionary 6:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 3}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [3, 2]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 2}} \n",
      "\n",
      "Dictionary 7:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 3}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [3, 3]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 3}} \n",
      "\n",
      "Dictionary 8:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 3}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [3, 4]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 4}} \n",
      "\n",
      "Dictionary 9:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 4}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [4, 3]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 3}} \n",
      "\n",
      "Dictionary 10:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 4}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [4, 4]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 4}} \n",
      "\n",
      "Dictionary 11:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 4}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [4, 5]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 5}} \n",
      "\n",
      "Dictionary 12:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 5}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [5, 4]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 4}} \n",
      "\n",
      "Dictionary 13:\n",
      "  by: name \n",
      "\n",
      "  default: {'config': {'name': None}} \n",
      "\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': 5}} \n",
      "\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [5, 5]}} \n",
      "\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': 5}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_multipliers = [(1,1), (1,2), (2,1), (2,2),(2,3),(3,2),(3,3),(3,4),(4,3),(4,4),(4,5),(5,4),(5,5)]\n",
    "  \n",
    "combinations = []\n",
    "for multiplier_a,multiplier_b in channel_multipliers:\n",
    "    new_config = pass_config_3.copy()  # Copy the original config\n",
    "    print(multiplier_a,multiplier_b)\n",
    "    for key in pass_config_3:\n",
    " \n",
    "        if key.startswith(\"seq_blocks\"):\n",
    "            if key.endswith(\"2\"):\n",
    "                # For each multiplier, create a new dict with updated multiplier\n",
    "                new_config[key] = new_config[key].copy()  # Copy the seq_block dict\n",
    "                new_config[key]['config'] = new_config[key]['config'].copy()  # Copy the config dict\n",
    "                new_config[key]['config']['channel_multiplier'] = multiplier_a  # Update multiplier\n",
    " \n",
    "            if key.endswith(\"4\"):\n",
    "                # For each multiplier, create a new dict with updated multiplier]                \n",
    "                new_config[key] = new_config[key].copy()  # Copy the seq_block dict\n",
    "                new_config[key]['config'] = new_config[key]['config'].copy()  # Copy the config dict\n",
    "                new_config[key]['config']['channel_multiplier'] = [multiplier_a,multiplier_b]  # Update multiplier\n",
    "                # new_config[key]['config']['channel_multiplier'][1] = multiplier_b  # Update multiplier\n",
    " \n",
    "            if key.endswith(\"6\"):\n",
    "                # For each multiplier, create a new dict with updated multiplier]                \n",
    "                new_config[key] = new_config[key].copy()  # Copy the seq_block dict\n",
    "                new_config[key]['config'] = new_config[key]['config'].copy()  # Copy the config dict\n",
    "                new_config[key]['config']['channel_multiplier'] = multiplier_b  # Update multiplier\n",
    "            \n",
    "    combinations.append(new_config)\n",
    " \n",
    " \n",
    " \n",
    "for i, d in enumerate(combinations, start=1):\n",
    "    print(f\"Dictionary {i}:\")\n",
    "    for key, value in d.items():\n",
    "        print(f\"  {key}: {value}\", '\\n')\n",
    "    \n",
    "#mg, _ = redefine_linear_transform_pass_non_uniform(graph=mg, pass_args={\"config\": pass_config})\n",
    " \n",
    "#print(mg.modules['seq_blocks_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Multiplier: [1, 1] \n",
      "\n",
      "start\n",
      "None\n",
      "None\n",
      "None\n",
      "['output_only']\n",
      "0 output_only\n",
      "None\n",
      "['input_only', 'output_only']\n",
      "0 input_only\n",
      "1 output_only\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m new_mg \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(mg)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#Function to redefine the linear transform\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m new_mg , _ \u001b[38;5;241m=\u001b[39m \u001b[43mredefine_linear_transform_pass_non_uniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_mg\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_blocks\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[120], line 36\u001b[0m, in \u001b[0;36mredefine_linear_transform_pass_non_uniform\u001b[0;34m(graph, pass_args)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_only\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     35\u001b[0m         in_features \u001b[38;5;241m=\u001b[39m in_features \u001b[38;5;241m*\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_multiplier\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 36\u001b[0m new_module \u001b[38;5;241m=\u001b[39m \u001b[43minstantiate_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m parent_name, name \u001b[38;5;241m=\u001b[39m get_parent_name(node\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28msetattr\u001b[39m(graph\u001b[38;5;241m.\u001b[39mmodules[parent_name], name, new_module)\n",
      "Cell \u001b[0;32mIn[120], line 4\u001b[0m, in \u001b[0;36minstantiate_linear\u001b[0;34m(in_features, out_features, bias)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mase/lib/python3.10/site-packages/torch/nn/modules/linear.py:98\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from chop.passes.graph.transforms import (\n",
    "    quantize_transform_pass,\n",
    "    summarize_quantization_analysis_pass,\n",
    ")\n",
    "\n",
    "# mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "# mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "# mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "metric = MulticlassAccuracy(num_classes=5)\n",
    "num_batchs = 5\n",
    "# This first loop is basically our search strategy,\n",
    "# in this case, it is a simple brute force search\n",
    "\n",
    "recorded_accs = []\n",
    "for i, pass_config in enumerate(combinations):\n",
    "\n",
    "    # print the config multiplier\n",
    "    print('Config Multiplier:', pass_config['seq_blocks_4']['config']['channel_multiplier'], '\\n')\n",
    "    \n",
    "    # we need to make a deep copy of the graph and the config so that the original graph is used when we multiply the channels\n",
    "    config = copy.deepcopy(pass_config)\n",
    "    new_mg = copy.deepcopy(mg)\n",
    "\n",
    "    #Function to redefine the linear transform\n",
    "    new_mg , _ = redefine_linear_transform_pass_non_uniform(graph=new_mg, pass_args={\"config\": config})\n",
    "    print(new_mg.modules['seq_blocks'], '\\n')\n",
    "\n",
    "    j = 0\n",
    "\n",
    "    # this is the inner loop, where we also call it as a runner.\n",
    "    acc_avg, loss_avg = 0, 0\n",
    "    accs, losses = [], []\n",
    "    \n",
    "    for inputs in data_module.train_dataloader():\n",
    "        xs, ys = inputs\n",
    "        preds = mg.model(xs)\n",
    "        loss = torch.nn.functional.cross_entropy(preds, ys)\n",
    "        acc = metric(preds, ys)\n",
    "        accs.append(acc)\n",
    "        losses.append(loss)\n",
    "        if j > num_batchs:\n",
    "            break\n",
    "        j += 1\n",
    "    acc_avg = sum(accs) / len(accs)\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "    recorded_accs.append(acc_avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary 1:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [1]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [1, 1]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [1]}}\n",
      "\n",
      "Dictionary 2:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [1]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [1, 2]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [2]}}\n",
      "\n",
      "Dictionary 3:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [2]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [2, 1]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [1]}}\n",
      "\n",
      "Dictionary 4:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [2]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [2, 2]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [2]}}\n",
      "\n",
      "Dictionary 5:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [2]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [2, 3]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [3]}}\n",
      "\n",
      "Dictionary 6:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [3]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [3, 2]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [2]}}\n",
      "\n",
      "Dictionary 7:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [3]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [3, 3]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [3]}}\n",
      "\n",
      "Dictionary 8:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [3]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [3, 4]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [4]}}\n",
      "\n",
      "Dictionary 9:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [4]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [4, 3]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [3]}}\n",
      "\n",
      "Dictionary 10:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [4]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [4, 4]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [4]}}\n",
      "\n",
      "Dictionary 11:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [4]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [4, 5]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [5]}}\n",
      "\n",
      "Dictionary 12:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [5]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [5, 4]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [4]}}\n",
      "\n",
      "Dictionary 13:\n",
      "  by: name\n",
      "  default: {'config': {'name': None}}\n",
      "  seq_blocks_2: {'config': {'names': ['output_only'], 'channel_multiplier': [5]}}\n",
      "  seq_blocks_4: {'config': {'names': ['input_only', 'output_only'], 'channel_multiplier': [5, 5]}}\n",
      "  seq_blocks_6: {'config': {'names': ['input_only'], 'channel_multiplier': [5]}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pass_config = {\n",
    "\"by\": \"name\",\n",
    "\"default\": {\"config\": {\"name\": None}},\n",
    "\"seq_blocks_2\": {\n",
    "    \"config\": {\n",
    "        \"names\": [\"output_only\"],\n",
    "        # weight\n",
    "        \"channel_multiplier\": [2],\n",
    "        }\n",
    "    },\n",
    "\"seq_blocks_4\": {\n",
    "    \"config\": {\n",
    "        \"names\": [\"input_only\",\"output_only\"],\n",
    "        \"channel_multiplier\": [2,2],\n",
    "        }\n",
    "    },\n",
    "\"seq_blocks_6\": {\n",
    "    \"config\": {\n",
    "        \"names\": [\"input_only\"],\n",
    "        \"channel_multiplier\": [2],\n",
    "        }\n",
    "    },\n",
    "}\n",
    " \n",
    " \n",
    "def redefine_linear_transform_pass_2(graph, pass_args=None):\n",
    "    #print('start')\n",
    "    main_config = pass_args.pop('config')\n",
    "    default = main_config.pop('default', None)\n",
    "    if default is None:\n",
    "        raise ValueError(f\"default value must be provided.\")\n",
    "    i = 0\n",
    "    for node in graph.fx_graph.nodes:\n",
    "        i += 1\n",
    "        # if node name is not matched, it won't be tracked\n",
    "        config = main_config.get(node.name, default)['config']\n",
    "        names = config.get(\"names\", None)\n",
    "        #print(names)\n",
    "        if names is not None:\n",
    "            ori_module = graph.modules[node.target]\n",
    "            in_features = ori_module.in_features\n",
    "            out_features = ori_module.out_features\n",
    "            bias = ori_module.bias\n",
    "            for i, name in enumerate(names):\n",
    "                #print(i,name)\n",
    "                if name == \"output_only\":\n",
    "                    out_features = out_features * config[\"channel_multiplier\"][i]\n",
    "                elif name == \"both\":\n",
    "                    in_features = in_features * config[\"channel_multiplier\"][i]\n",
    "                    out_features = out_features * config[\"channel_multiplier\"][i]\n",
    "                elif name == \"input_only\":\n",
    "                    in_features = in_features * config[\"channel_multiplier\"][i]\n",
    "            new_module = instantiate_linear(in_features, out_features, bias)\n",
    "            parent_name, name = get_parent_name(node.target)\n",
    "            setattr(graph.modules[parent_name], name, new_module)\n",
    "    return graph, {}\n",
    " \n",
    "import copy\n",
    "\n",
    "mg = MaseGraph(model=model)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "  \n",
    "channel_multipliers = [(1,1), (1,2), (2,1), (2,2),(2,3),(3,2),(3,3),(3,4),(4,3),(4,4),(4,5),(5,4),(5,5)]\n",
    "  \n",
    "combinations = []\n",
    "for multiplier_a,multiplier_b in channel_multipliers:\n",
    "    new_config = pass_config.copy()  # Copy the original config\n",
    "    #print(multiplier_a,multiplier_b)\n",
    "    for key in pass_config:\n",
    " \n",
    "        if key.startswith(\"seq_blocks\"):\n",
    "            if key.endswith(\"2\"):\n",
    "                # For each multiplier, create a new dict with updated multiplier\n",
    "                new_config[key] = new_config[key].copy()  # Copy the seq_block dict\n",
    "                new_config[key]['config'] = new_config[key]['config'].copy()  # Copy the config dict\n",
    "                new_config[key]['config']['channel_multiplier'] = [multiplier_a]  # Update multiplier\n",
    " \n",
    "            if key.endswith(\"4\"):\n",
    "                # For each multiplier, create a new dict with updated multiplier           \n",
    "                new_config[key] = new_config[key].copy()  # Copy the seq_block dict\n",
    "                new_config[key]['config'] = new_config[key]['config'].copy()  # Copy the config dict\n",
    "                new_config[key]['config']['channel_multiplier'] = [multiplier_a,multiplier_b]  # Update multiplier\n",
    "                \n",
    "            if key.endswith(\"6\"):\n",
    "                # For each multiplier, create a new dict with updated multiplier]                \n",
    "                new_config[key] = new_config[key].copy()  # Copy the seq_block dict\n",
    "                new_config[key]['config'] = new_config[key]['config'].copy()  # Copy the config dict\n",
    "                new_config[key]['config']['channel_multiplier'] = [multiplier_b]  # Update multiplier\n",
    "            \n",
    "    combinations.append(new_config)\n",
    "  \n",
    "for i, d in enumerate(combinations, start=1):\n",
    "    print(f\"Dictionary {i}:\")\n",
    "    for key, value in d.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print()  # Print a blank line for spacing between dictionaries\n",
    " \n",
    "#mg, _ = redefine_linear_transform_pass_2(graph=mg, pass_args={\"config\": pass_config})\n",
    " \n",
    "#print(mg.modules['seq_blocks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Multiplier: [1, 1] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=64, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [1, 2] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=32, out_features=128, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [2, 1] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=64, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=64, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [2, 2] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=64, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [2, 3] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=64, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=64, out_features=192, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=192, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [3, 2] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=96, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=96, out_features=128, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [3, 3] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=96, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=96, out_features=192, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=192, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [3, 4] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=96, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=96, out_features=256, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=256, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [4, 3] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=128, out_features=192, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=192, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [4, 4] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=256, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [4, 5] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=128, out_features=320, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=320, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [5, 4] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=160, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=160, out_features=256, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=256, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n",
      "Config Multiplier: [5, 5] \n",
      "\n",
      "Module(\n",
      "  (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Linear(in_features=16, out_features=160, bias=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Linear(in_features=160, out_features=320, bias=True)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): Linear(in_features=320, out_features=5, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from chop.passes.graph.transforms import (\n",
    "    quantize_transform_pass,\n",
    "    summarize_quantization_analysis_pass,\n",
    ")\n",
    "\n",
    "# mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "# mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "# mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "metric = MulticlassAccuracy(num_classes=5)\n",
    "num_batchs = 5\n",
    "# This first loop is basically our search strategy,\n",
    "# in this case, it is a simple brute force search\n",
    "\n",
    "recorded_accs = []\n",
    "for i, pass_config in enumerate(combinations):\n",
    "\n",
    "    # print the config multiplier\n",
    "    print('Config Multiplier:', pass_config['seq_blocks_4']['config']['channel_multiplier'], '\\n')\n",
    "    \n",
    "    # we need to make a deep copy of the graph and the config so that the original graph is used when we multiply the channels\n",
    "    config = copy.deepcopy(pass_config)\n",
    "    new_mg = copy.deepcopy(mg)\n",
    "\n",
    "    #Function to redefine the linear transform\n",
    "    new_mg , _ = redefine_linear_transform_pass_2(graph=new_mg, pass_args={\"config\": config})\n",
    "    print(new_mg.modules['seq_blocks'], '\\n')\n",
    "\n",
    "    j = 0\n",
    "\n",
    "    # this is the inner loop, where we also call it as a runner.\n",
    "    acc_avg, loss_avg = 0, 0\n",
    "    accs, losses = [], []\n",
    "    \n",
    "    for inputs in data_module.train_dataloader():\n",
    "        xs, ys = inputs\n",
    "        preds = mg.model(xs)\n",
    "        loss = torch.nn.functional.cross_entropy(preds, ys)\n",
    "        acc = metric(preds, ys)\n",
    "        accs.append(acc)\n",
    "        losses.append(loss)\n",
    "        if j > num_batchs:\n",
    "            break\n",
    "        j += 1\n",
    "    acc_avg = sum(accs) / len(accs)\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "    recorded_accs.append(acc_avg)\n",
    "\n",
    "    pass_config['seq_blocks_4']['config']['channel_multiplier'] = [multiplier_a, multiplier_b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1774)\n",
      "[tensor(0.1726), tensor(0.2786), tensor(0.1560), tensor(0.2470), tensor(0.1786), tensor(0.1036), tensor(0.2262), tensor(0.2345), tensor(0.1762), tensor(0.1060), tensor(0.2944), tensor(0.1429), tensor(0.1774)]\n"
     ]
    }
   ],
   "source": [
    "print(acc_avg)\n",
    "print(recorded_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you then design a search so that it can reach a network that can have this kind of structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Integrate the search to the `chop` flow, so we can run it from the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional task (scaling the search to real networks)\n",
    "\n",
    "We have looked at how to search, on the architecture level, for a simple linear layer based network. MASE has the following components that you can have a look:\n",
    "\n",
    "* [Cifar10 dataset](https://github.com/DeepWok/mase/blob/main/machop/chop/dataset/vision/cifar.py)\n",
    "* [VGG](https://github.com/DeepWok/mase/blob/main/machop/chop/models/vision/vgg_cifar/vgg_cifar.py), this is a variant used for CIFAR\n",
    "* [TPE-based Search](https://github.com/DeepWok/mase/blob/main/machop/chop/actions/search/strategies/optuna.py), implementd using [Optuna](https://optuna.readthedocs.io/en/stable/reference/index.html)\n",
    "\n",
    "Can you define a search space (maybe channel dimension) for the VGG network, and use the TPE-search to tune it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
